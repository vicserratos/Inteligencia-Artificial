{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "class CargaDatos():\n",
    "\n",
    "    # Se cargan los datos de entrenamiento y prueba se etiquetan y se dividen en dos partes\n",
    "    # porcentajeEntrenamiento es el tamaño del subconjuto de entrenamiento en porcentaje, el valor dado es de entrenamiento y el restante es de prueba\n",
    "    # TamanioSet es el tamaño del set de entrenamiento que vamos a tomar, entre mas grande mas tiempo toma.\n",
    "    def cargaDatosEntrenamiento(self, tamanioSet, porcentajeEntrenamiento):\n",
    "        path = \"data/entrenamiento\"\n",
    "        textos = []\n",
    "\n",
    "        for etiqueta in [\"pos\", \"neg\"]:\n",
    "            pathTexto = path + \"/\" + etiqueta\n",
    "            self.auxCargaDatosEntrenamiento(pathTexto, textos, etiqueta)   \n",
    "        random.shuffle(textos)\n",
    "\n",
    "        if tamanioSet:\n",
    "            textos = textos[:tamanioSet]\n",
    "        porcentajeEntrenamiento = int(len(textos) * porcentajeEntrenamiento)\n",
    "        return textos[:porcentajeEntrenamiento], textos[porcentajeEntrenamiento:]\n",
    "\n",
    "    # Carga y etiqueta los textos asiganndo una categoria dentro de spacy\n",
    "    def auxCargaDatosEntrenamiento(self, pathTexto, textos, etiqueta):\n",
    "        for archivoTexto in os.listdir(pathTexto):\n",
    "            with open(f\"{pathTexto}/{archivoTexto}\") as f:\n",
    "                texto = f.read()\n",
    "                texto = texto.replace(\"<br />\", \"\\n\\n\")\n",
    "                #print(texto)\n",
    "                if texto.strip():\n",
    "                    spacy_cats = { \"cats\": {\n",
    "                                            \"pos\" : \"pos\" == etiqueta,\n",
    "                                            \"neg\" : \"neg\" == etiqueta,\n",
    "                                            }\n",
    "                    }\n",
    "                    textos.append((texto, spacy_cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "class Entrenamiento:\n",
    "    \n",
    "    def entrenaModelo(self, setEntrenamiento, setTest, iteraciones, excluirSubSet):\n",
    "        # textcat() es un categorizador de texto, sobre un texto dado realiza la clasificación sobre un texto.\n",
    "        # Se le proporcionan etiquetas, de la cual sólo le corre´ponde una a cada texto\n",
    "        # Proporciona varias arquitecturas y utilizamos una red neuronal de convolucion (CNN) ya predefinida\n",
    "        nlp = en_core_web_sm.load()\n",
    "        print(\"Nuestro Procesador de lenguaje natural utilizará una red neuronal de convolución\")\n",
    "        textcat = nlp.create_pipe( \"textcat\", config={\"architecture\": \"simple_cnn\"})\n",
    "        nlp.add_pipe(textcat)\n",
    "        textcat.add_label(\"pos\")\n",
    "        textcat.add_label(\"neg\")\n",
    "        \n",
    "        # Se ejecuta sólo texcat y no otros modelos\n",
    "        pipesSinTextcat = nlp.pipe_names\n",
    "        pipesSinTextcat.remove('textcat')\n",
    "\n",
    "        with nlp.disable_pipes(pipesSinTextcat):\n",
    "\n",
    "            # Regresa una función optimizadora la cual nos sirve para actualizar los pesos en el modelo            \n",
    "            funOptimizadora = nlp.begin_training()\n",
    "            #Excluye en porcentaje un subconjunto de conjunto de entrenamiento, esto permite que no sea el mismo entrenamiento en las pasadas\n",
    "            i = 0\n",
    "            imprime = True\n",
    "            # Se generan \"n\" entrenamientos\n",
    "            for i in range(iteraciones):\n",
    "                print(\"Entrenamiento #: \", str(i))\n",
    "                perdidas = {}\n",
    "                random.shuffle(setEntrenamiento)\n",
    "                for dato in setEntrenamiento:\n",
    "                    tweet, etiquetas = zip(dato)\n",
    "                    # print(tweet, etiquetas)\n",
    "                    # Actualiza los pesos del modelo\n",
    "                    nlp.update(tweet, etiquetas, excluirSubSet, funOptimizadora, perdidas)\n",
    "                    if(i < 1):\n",
    "                        print(\"Ejemplo de Promedios FuncOpt: \")\n",
    "                        print(funOptimizadora.averages)\n",
    "                        i += 1\n",
    "                        imprime = False\n",
    "                with textcat.model.use_params(funOptimizadora.averages):\n",
    "                    resultados = self.evaluaModelo(nlp.tokenizer, textcat, setTest, imprime)\n",
    "                print(\"Prueba del modelo\")\n",
    "                print(\"Gradiente de Perdida \\tCalculo \\tRecall \\tF-score\")\n",
    "                print(perdidas['textcat'], \"\\t\", resultados['calculo'], \"\\t\", resultados['recall'], \"\\t\", resultados['f-score'])\n",
    "                print()\n",
    "        # Se guarda el modelo para no hacer el calculo cada ejecución\n",
    "        with nlp.use_params(funOptimizadora.averages):\n",
    "            nlp.to_disk(\"modeloData\")\n",
    "\n",
    "    # Evalua el modelo\n",
    "    # El calculo es que tan preciso fue ser un verdadero positivo\n",
    "    # Es la proporcion de verdaderos positivos\n",
    "    # F-score es el rendimeinto de la funcion\n",
    "    def evaluaModelo(self, tokenizer, textcat, setTest, imprime) -> dict:\n",
    "        print(\"Evalua Modelo\")\n",
    "        tweets, etiquetas = zip(*setTest)\n",
    "        tweets = (tokenizer(tweet) for tweet in tweets)\n",
    "        positivosVerdaderos = 0\n",
    "        falsosPositivos = 1e-8  \n",
    "        negativosVerdaderos = 0\n",
    "        falsosNegativos = 1e-8\n",
    "        for i, tweet in enumerate(textcat.pipe(tweets)):\n",
    "            etiquetaCat = etiquetas[i][\"cats\"]\n",
    "            for prediccion, score in tweet.cats.items():\n",
    "                if(imprime):\n",
    "                    print(\"\\nEjemplo de Prediccion del tweet :\", tweet.text)\n",
    "                    print(\"Predicción: \", str(prediccion), \"Score: \", str(score))\n",
    "                if prediccion == \"neg\":\n",
    "                    continue\n",
    "                if score >= 0.5 and etiquetaCat[\"pos\"]:\n",
    "                    positivosVerdaderos += 1\n",
    "                elif score >= 0.5 and etiquetaCat[\"neg\"]:\n",
    "                    falsosPositivos += 1\n",
    "                elif score < 0.5 and etiquetaCat[\"neg\"]:\n",
    "                    negativosVerdaderos += 1\n",
    "                elif score < 0.5 and etiquetaCat[\"pos\"]:\n",
    "                    falsosNegativos += 1\n",
    "        calculo = positivosVerdaderos / (positivosVerdaderos + falsosPositivos)\n",
    "        recall = positivosVerdaderos / (positivosVerdaderos + falsosNegativos)\n",
    "\n",
    "        if calculo + recall == 0:\n",
    "            f_score = 0\n",
    "        else:\n",
    "            f_score = 2 * (calculo * recall) / (calculo + recall)\n",
    "        return {\"calculo\": calculo, \"recall\": recall, \"f-score\": f_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "class Tokenizer():\n",
    "\t\n",
    "\tdef ejemplo(self, texto):\n",
    "\n",
    "\t\tprint(\"Tweet: \", texto)\n",
    "\n",
    "\t\t#Eliminamos puntuacion\n",
    "\t\ttexto = texto.translate(str.maketrans('', '', string.punctuation))\n",
    "\t\tprint(\"tweet sin puntuacion: \", texto, \"\\n\")\n",
    "\n",
    "\t\t# Construye el procesador de lenguaje natural\n",
    "\t\tconstruccion = nlp (texto)\n",
    "\n",
    "\t\t# Tokeniza el texto\n",
    "\t\tlista_tokens = [token for token in construccion]\n",
    "\t\tprint(\"Lista tokens: \", str(lista_tokens), \"\\n\")\n",
    "\n",
    "\t\t# Genera una lista de tokens filtrada.\n",
    "\t\t# El filtro consiste en eliminar palabras conectora o vacias como \"pero\", \"o\", \"entonces\", etc.\n",
    "\t\ttokens_filtrados = [token for token in construccion if not token.is_stop]\n",
    "\t\tprint(\"Lista Tokens filtrada: \", tokens_filtrados, \"\\n\")\n",
    "\n",
    "\t\t#Spicy nos ayuda a normalizar el texto, es decir, las palabras las convierte a su raíz\n",
    "\t\t# Ejemplo: doctor, doctores, doctoras -> doctor\n",
    "\t\t# Hay dos formas de normalizar: Derivación y por lemas, Spicy utiliza Lemas\n",
    "\t\t# Spicy lo hace forma automatica así que se imprime el ejemplo de como funciona\n",
    "\t\tlemas = [\n",
    "\t\t    f\"Token: {token}, lemma: {token.lemma_}\"\n",
    "\t\t    for token in tokens_filtrados\n",
    "\t\t]\n",
    "\t\tprint(\"Ejemplo de lemas: \", lemas, \"\\n\")\n",
    "\n",
    "\t\t# El siguiente paso es la vectorizacion del texto, lo que se realiza es transformar un token en una matriz\n",
    "\t\t# Esta matriz en PNL es unica y tiene representadas varias caracteristicas de un token.\n",
    "\t\t# Esto nos sirve para clasificar el texto dadas sus similitudes.\n",
    "\t\tprint(\"Vectorizacion de palabras. Ejemplo: \", tokens_filtrados[3], \"\\n\", tokens_filtrados[3].vector, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Ejecuta el modelo generado y spacy calcula el sentimiento del tweet\n",
    "class CalculaSentimiento:\n",
    "\n",
    "    def getSentimiento(self, texto):\n",
    "        modelo = spacy.load(\"modeloData\")\n",
    "        # Entrega el analisis\n",
    "        analisis = modelo(texto)\n",
    "        # De acuerdo al analisis se obtiene el valor que se daria como \"positivo\" y el \"negativo\", de acuerdo a eso se obtiene el sentimiento y el score\n",
    "        print(\"analisis de pos: \", str(analisis.cats[\"pos\"]))\n",
    "        print(\"analisis de neg: \", str(analisis.cats[\"neg\"]))\n",
    "        if analisis.cats[\"pos\"] > analisis.cats[\"neg\"]:\n",
    "            calculo = \"Positivo :)\"\n",
    "            score = analisis.cats[\"pos\"]\n",
    "        else:\n",
    "            calculo = \"Negativo :(\"\n",
    "            score = analisis.cats[\"neg\"]\n",
    "        print(\"Tweet: \", texto, \"\\n\", \"Sentimiento calculado: \", calculo, \"\\t\", \"Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Que deseas hacer?\n",
      "\ta. Entrenar un modelo nuevo\n",
      "\n",
      "\tb. Calcular sentimientos (Ya tienes un modelo entrenado)\n",
      "Ingresa a o b:  a\n",
      "\n",
      "Define los siguientes valores: \n",
      "\tTamaño del conjunto de entrenamiento\n",
      "Ingresa número natural:  800\n",
      "\tPorcentaje del tamaño del conjunto de entrenamiento\n",
      "Ingresa número entre 0 y 1:  .7\n",
      "\tIteraciones de entrenamiento\n",
      "Ingresa número natural:  5\n",
      "\tDel subconjunto obtenido de entrenamiento da un porcentaje que quieres utilizar\n",
      "Ingresa número entre 0 y 1:  .2\n",
      "Cargando datos\n",
      "\n",
      "El tamaño definido es:  800\n",
      "Porcentaje de set entrenamiento:  0.7\n",
      "Porcentaje tamaño set prueba:  0.3\n",
      "\n",
      "Generando modelo de entrenamiento\n",
      "\n",
      "Nuestro Procesador de lenguaje natural utilizará una red neuronal de convolución\n",
      "Entrenamiento #:  0\n",
      "Ejemplo de Promedios FuncOpt: \n",
      "{1308: array([ 0.06351852, -0.01922114,  0.11990304,  0.19090739, -0.12687938,\n",
      "        0.11638042,  0.06476531,  0.09938527,  0.2010478 , -0.14833684,\n",
      "        0.08256114,  0.0115979 , -0.01837107, -0.03260564,  0.19109139,\n",
      "        0.14936352,  0.1652141 , -0.1625361 ,  0.15439059,  0.04822202,\n",
      "        0.18914925,  0.09541644, -0.14188969,  0.06255952, -0.09262886,\n",
      "        0.03246505,  0.19587642,  0.01318359, -0.10058623,  0.05585473,\n",
      "        0.19386907,  0.04699494, -0.10618334,  0.15633917,  0.1443354 ,\n",
      "        0.18215321,  0.04958307, -0.0578249 ,  0.12113743,  0.19210017,\n",
      "       -0.12497709,  0.06784093,  0.07574546, -0.02760092, -0.02316225,\n",
      "       -0.05932523, -0.0526419 , -0.05960516, -0.12218896, -0.13336717,\n",
      "       -0.17265186, -0.065579  ,  0.0191867 ,  0.14301747,  0.10723346,\n",
      "        0.00515112,  0.03686447, -0.15780531,  0.0988318 ,  0.13194203,\n",
      "        0.12653837,  0.14149554,  0.12804887,  0.12933162, -0.10859002,\n",
      "       -0.07938049,  0.08737515, -0.11963344, -0.16953452, -0.01852471,\n",
      "       -0.13678667,  0.048928  , -0.17444304,  0.12878771,  0.04418243,\n",
      "       -0.07210776,  0.19694757, -0.00240991,  0.10504021,  0.14180867,\n",
      "       -0.06623908,  0.01199991, -0.02481701, -0.1276329 ,  0.14778094,\n",
      "       -0.13002811,  0.06875451,  0.1608362 , -0.04907213, -0.1284672 ,\n",
      "        0.02781907, -0.14528584, -0.1438489 ,  0.12474058,  0.12548956,\n",
      "       -0.10228813,  0.05553504, -0.04677896,  0.08373819, -0.12995455,\n",
      "       -0.18992423,  0.16878827,  0.0480215 , -0.09563864, -0.19709694,\n",
      "        0.14232749,  0.12401358, -0.08872151,  0.12387458, -0.08081674,\n",
      "        0.07581468, -0.10663599, -0.19624157,  0.15036775, -0.13189618,\n",
      "       -0.14169808,  0.09187121,  0.0210832 , -0.01970707,  0.1298429 ,\n",
      "       -0.01522646, -0.10371405,  0.02167202, -0.19425477, -0.1499613 ,\n",
      "       -0.01928064, -0.1773237 ,  0.00740058,  0.01789185,  0.15577766,\n",
      "       -0.05398545,  0.14606073, -0.00676817,  0.04452361, -0.16760837,\n",
      "       -0.19017719, -0.11941413, -0.10360293,  0.1352755 , -0.1404299 ,\n",
      "       -0.02217415, -0.18534194, -0.16156153, -0.14686726,  0.02959962,\n",
      "        0.11920003, -0.07691842, -0.17062809, -0.02257429, -0.0574987 ,\n",
      "       -0.03570423,  0.18273059,  0.18121208,  0.173396  , -0.10550638,\n",
      "        0.02460425, -0.10001471,  0.08154839,  0.09480714, -0.16628705,\n",
      "        0.09100261,  0.1221237 , -0.03940789,  0.1858004 ,  0.03775168,\n",
      "       -0.00437481,  0.12583755,  0.1795513 ,  0.07429643, -0.01183999,\n",
      "        0.17676233, -0.10855912, -0.11555894, -0.18762437, -0.19506678,\n",
      "        0.12982135,  0.09537996,  0.16227946,  0.01469666,  0.14431936,\n",
      "        0.15448588, -0.03549082, -0.20143797, -0.17219949,  0.13272272,\n",
      "        0.01090363, -0.01774993,  0.01167132, -0.19712849, -0.14545453,\n",
      "       -0.03941318,  0.19305068, -0.00081819,  0.00081819], dtype=float32), 1343: array([ 8.1736392e-01,  8.1756020e-01,  8.1736374e-01,  8.1736374e-01,\n",
<<<<<<< HEAD
      "        ...,\n",
      "        ...,\n",
=======
      "        ...
      "        ...
>>>>>>> 5da06ada0c459fa5ab0c0047e87e01c6a50e2099
      "        0.00081818,  0.00081816], dtype=float32), 1319: array([ 0.01151618,  0.00753843,  0.03696552, ..., -0.00063783,\n",
      "       -0.07191614, -0.010942  ], dtype=float32), 1320: array([ 0.04020756,  0.0768711 , -0.022243  , ...,  0.03439475,\n",
      "       -0.05881651, -0.07859924], dtype=float32), 1321: array([-0.01824459,  0.07552894,  0.0406008 , ..., -0.06289636,\n",
      "       -0.02700866,  0.03304522], dtype=float32), 1322: array([-0.01128165,  0.04103797,  0.00167407, ...,  0.02520496,\n",
      "       -0.00697506,  0.075271  ], dtype=float32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalua Modelo\n",
      "Prueba del modelo\n",
      "Gradiente de Perdida \tCalculo \tRecall \tF-score\n",
      "554.0026105057423 \t 0.48749999997968746 \t 0.9999999999145299 \t 0.655462184837229\n",
      "\n",
      "Entrenamiento #:  1\n",
      "Evalua Modelo\n",
      "Prueba del modelo\n",
      "Gradiente de Perdida \tCalculo \tRecall \tF-score\n",
      "517.1828493771826 \t 0.0 \t 0.0 \t 0\n",
      "\n",
      "Entrenamiento #:  2\n",
      "Evalua Modelo\n",
      "Prueba del modelo\n",
      "Gradiente de Perdida \tCalculo \tRecall \tF-score\n",
      "559.9467740058899 \t 0.0 \t 0.0 \t 0\n",
      "\n",
      "Entrenamiento #:  3\n",
      "Evalua Modelo\n",
      "Prueba del modelo\n",
      "Gradiente de Perdida \tCalculo \tRecall \tF-score\n",
      "559.2049914586444 \t 0.48749999997968746 \t 0.9999999999145299 \t 0.655462184837229\n",
      "\n",
      "Entrenamiento #:  4\n",
      "Evalua Modelo\n",
      "Prueba del modelo\n",
      "Gradiente de Perdida \tCalculo \tRecall \tF-score\n",
      "557.4838334118701 \t 0.0 \t 0.0 \t 0\n",
      "\n",
      "\n",
      "¡¡¡ Fin del entrenamiento !!!\n",
      "\n",
      "Vamos a cualcular un sentimiento\n",
      "Introduce tu tweet: RT @clarionledger: Diabetes, COVID-19 combination poses high risk for Black and Hispanic patients, study finds https://t.co/YwaAgHW6Ik\n",
      "\n",
      "Ejemplo de Tokenizer\n",
      "Tweet:  RT @clarionledger: Diabetes, COVID-19 combination poses high risk for Black and Hispanic patients, study finds https://t.co/YwaAgHW6Ik\n",
      "tweet sin puntuacion:  RT clarionledger Diabetes COVID19 combination poses high risk for Black and Hispanic patients study finds httpstcoYwaAgHW6Ik \n",
      "\n",
      "Lista tokens:  [RT, clarionledger, Diabetes, COVID19, combination, poses, high, risk, for, Black, and, Hispanic, patients, study, finds, httpstcoYwaAgHW6Ik] \n",
      "\n",
      "Lista Tokens filtrada:  [RT, clarionledger, Diabetes, COVID19, combination, poses, high, risk, Black, Hispanic, patients, study, finds, httpstcoYwaAgHW6Ik] \n",
      "\n",
      "Ejemplo de lemas:  ['Token: RT, lemma: RT', 'Token: clarionledger, lemma: clarionledger', 'Token: Diabetes, lemma: diabetes', 'Token: COVID19, lemma: COVID19', 'Token: combination, lemma: combination', 'Token: poses, lemma: pose', 'Token: high, lemma: high', 'Token: risk, lemma: risk', 'Token: Black, lemma: black', 'Token: Hispanic, lemma: hispanic', 'Token: patients, lemma: patient', 'Token: study, lemma: study', 'Token: finds, lemma: find', 'Token: httpstcoYwaAgHW6Ik, lemma: httpstcoywaaghw6ik'] \n",
      "\n",
      "Vectorizacion de palabras. Ejemplo:  COVID19 \n",
      " [ 2.4035592   1.3232589  -0.21049923 -0.37433437  3.229977    0.7206147\n",
      " -2.3952842   0.14889617 -3.6860428   2.6948333   3.4461188  -1.3590109\n",
      " -0.8859028   1.7225127  -1.9561485  -1.996666   -0.7921236   4.601231\n",
      " -3.4028766   1.3085564   3.500606    0.2628157   0.49692422  0.34123164\n",
      " -0.8635434   2.087903   -1.7126489  -2.5988295   0.26074436  0.5989594\n",
      " -1.309438    2.581842   -0.7488601  -1.9086571  -2.3486075  -2.4530232\n",
      "  0.8811884  -1.5894088   1.6422349   0.04874453  1.2812297   0.18173301\n",
      "  0.473328   -2.522144   -0.24752349 -0.04464233 -0.10585326  0.0081985\n",
      "  2.5090897   0.3968755  -3.2181492   1.4764358  -0.94888145 -0.90071446\n",
      "  0.22876877 -1.1176889  -1.5539926  -1.294272    0.4234414   1.1909811\n",
      " -0.27361912  3.391862    1.7061422  -1.5913639   0.35323733  0.36458063\n",
      "  0.15918648 -0.12075198  2.3689127   1.0461872  -0.5799826   2.159785\n",
      " -0.5644814  -3.5671606  -1.3268937  -1.086352    0.5359663   1.5189235\n",
      "  0.19955355 -2.0968676   0.78894323  0.43438518 -0.8240288   0.39063013\n",
      " -1.2312789   0.04115111  4.1492624  -0.5590972   2.1097937   0.3870229\n",
      "  0.0288952   1.6685723  -4.0688057   1.9950289  -2.534147    1.8792683 ] \n",
      "\n",
      "\n",
      "Calculando sentimiento\n",
      "analisis de pos:  4.539786823443137e-05\n",
      "analisis de neg:  4.539786823443137e-05\n",
      "Tweet:  RT @clarionledger: Diabetes, COVID-19 combination poses high risk for Black and Hispanic patients, study finds https://t.co/YwaAgHW6Ik \n",
      " Sentimiento calculado:  Negativo :( \t Score:  4.539786823443137e-05\n"
     ]
    }
   ],
   "source": [
    "class AnalizadorSentimientos:\n",
    "\n",
    "    def menu():\n",
    "        print(\"¿Que deseas hacer?\")\n",
    "        print(\"\\ta. Entrenar un modelo nuevo\\n\")\n",
    "        print(\"\\tb. Calcular sentimientos (Ya tienes un modelo entrenado)\")\n",
    "    \n",
    "        op = input(\"Ingresa a o b:  \")\n",
    "        if(op != \"a\"):\n",
    "            if(op != \"b\"):\n",
    "                return 0        \n",
    "        return op\n",
    "\n",
    "    def subMenu():\n",
    "        #tamanioSet = 30\n",
    "        #porcentajeEntrenamiento = 0.7\n",
    "        #iteraciones = 15\n",
    "        #excluirSubSet = .1\n",
    "        print(\"\\nDefine los siguientes valores: \")\n",
    "        print(\"\\tTamaño del conjunto de entrenamiento\")\n",
    "        tamanioSet = input(\"Ingresa número natural:  \")\n",
    "        print(\"\\tPorcentaje del tamaño del conjunto de entrenamiento\")\n",
    "        porcentajeEntrenamiento = input(\"Ingresa número entre 0 y 1:  \")\n",
    "        print(\"\\tIteraciones de entrenamiento\")\n",
    "        iteraciones = input(\"Ingresa número natural:  \")\n",
    "        print(\"\\tDel subconjunto obtenido de entrenamiento da un porcentaje que quieres utilizar\")\n",
    "        excluirSubSet = input(\"Ingresa número entre 0 y 1:  \")\n",
    "        return [tamanioSet, porcentajeEntrenamiento, iteraciones, excluirSubSet]\n",
    "\n",
    "    def getSentimiento():\n",
    "        print(\"\\nVamos a cualcular un sentimiento\")\n",
    "        tweet = input(\"Introduce tu tweet: \")\n",
    "\n",
    "        print(\"\\nEjemplo de Tokenizer\")\n",
    "        t = Tokenizer()\n",
    "        t.ejemplo(tweet)\n",
    "\n",
    "        print(\"\\nCalculando sentimiento\")\n",
    "        cs = CalculaSentimiento()      \n",
    "        cs.getSentimiento(tweet)\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        #palabrasClave = ['covid','coronavirus', 'lang:en']\n",
    "        #a = ApiTwitter()\n",
    "        #a.inicalizaStremTwitter(palabrasClave)\n",
    "        opcion = menu()\n",
    "        if(opcion == \"a\"):\n",
    "            resultados = subMenu()\n",
    "            tamanioSet = int(resultados[0])\n",
    "            porcentajeEntrenamiento = float(resultados[1])\n",
    "            iteraciones = int(resultados[2])\n",
    "            excluirSubSet = float(resultados[3])\n",
    "\n",
    "            cargaDatos = CargaDatos()\n",
    "            print(\"Cargando datos\\n\")\n",
    "            print(\"El tamaño definido es: \", str(tamanioSet))\n",
    "            print(\"Porcentaje de set entrenamiento: \", str(porcentajeEntrenamiento))\n",
    "            print(\"Porcentaje tamaño set prueba: \", str( -round(porcentajeEntrenamiento - 1, 1) ))\n",
    "            print()\n",
    "            setEntrenamiento, setTest = cargaDatos.cargaDatosEntrenamiento(tamanioSet, porcentajeEntrenamiento)\n",
    "            \n",
    "            entrenamiento = Entrenamiento()\n",
    "            print(\"Generando modelo de entrenamiento\\n\")\n",
    "            entrenamiento.entrenaModelo(setEntrenamiento, setTest, iteraciones, excluirSubSet)\n",
    "            print(\"\\n¡¡¡ Fin del entrenamiento !!!\")\n",
    "            getSentimiento()\n",
    "\n",
    "        if(opcion == \"b\"):\n",
    "            getSentimiento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @kwanwillsen: Indonesia, Myanmar, Singapore have started their vaccination programmes. Thailand in mid-February. \n",
      "\n",
      "In Malaysia, we are a…\n",
      "RT @TimBuchmanMDPhD: The latest Surviving Sepsis COVID-19 guidance was released today at @CritCareMed. Nine specific recommendations to bri…\n",
      "RT @JJHennie1: For the WH Twitter: ‘From COVID-19 and the economy to climate change and racial equity — President Biden has wasted no time…\n",
      "Viral Posts Distort WHO Guidance on COVID-19 Tests: https://t.co/Jp5gVdZHTK\n",
      "RT @TheBabylonBee: Governor Newsom ends COVID lockdowns by joyfully shouting reopen to rows of abandoned, dilapidated buildings throughout…\n",
      "RT @ARmastrangelo: More than 31,000 people in the U.S. have died from COVID under Joe Biden's leadership, during his first week in office.…\n",
      "RT @kilmeade: Dr Fauci has been doing this for 60 years and as of last March didnt think masks worked...what changed? When is he telling th…\n",
      "RT @CheyneJoness: DETAILS ON LATEST COVID-19 DEATH.\n",
      "\n",
      "Barbados yesterday recorded its twelfth death from Covid-19. The 84 year old female di…\n",
      "@washingtonpost WAPO, do you pay ANY attention to the reality of what’s going on before publishing? Geesh. Journali… https://t.co/NY3rRh1RDF\n",
      "RT @clarionledger: Diabetes, COVID-19 combination poses high risk for Black and Hispanic patients, study finds https://t.co/YwaAgHW6Ik\n",
      "@frogheed @SkyNews If u look at nhs England website it tells u underlying conditions people with covid die off diab… https://t.co/U4RCsVwart\n",
      "RT @ABC: NEW: There have been more COVID-19 cases reported globally in the past two weeks than during the first six months of the pandemic,…\n"
     ]
    },
<<<<<<< HEAD
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
     ]
    }
=======
>>>>>>> 5da06ada0c459fa5ab0c0047e87e01c6a50e2099
   ],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "#Tokens de acceso al API de Twitter\n",
    "access_token = \"1352454815612284928-FGSnN5KZBcaYBCn25uqCw5EFtCqq9N\"\n",
    "access_token_secret = \"eSpmmgm816u4LL7ri1H2TC03Zcl3pOtziJ2yNlTU7J9Ni\"\n",
    "api_key = \"7w0jQUpTHc1IHZ6n7IzlvUomr\"\n",
    "api_secret = \"xDURCkqYuUoMDhSWy9txzpx6q3EJByd0HUZ0PXijaDoUMsKjXA\"\n",
    "\n",
    "# Clase que recolecta tweets de acuerdo al tema que vamos a consultar\n",
    "class ApiTwitter():\n",
    "\n",
    "    class Streaming(StreamListener):\n",
    "      \n",
    "        file = open(\"tweets.txt\", \"a\")\n",
    "        \n",
    "        #def on_data(self, data):\n",
    "            #print(data)\n",
    "           # return True\n",
    "\n",
    "        # Cuando ocurre un error lo cacha e impide que se interrumpa el streaming\n",
    "        def on_error(self, status):\n",
    "            print(status)\n",
    "            \n",
    "        # Obtiene el tweet y se maneja de acuerdo a lo que queremos, \n",
    "        # en nuestro caso nos importa de momento el contenido de tweet.    \n",
    "        def on_status(self, status):\n",
    "            #print(status.retweeted_status)\n",
    "            self.file.write(status.text)\n",
    "            print(status.text)\n",
    "            \n",
    "\n",
    "\n",
    "    def inicalizaStremTwitter(self, palabrasClave): \n",
    "        #Inicializa el API\n",
    "        listener = self.Streaming()\n",
    "        oAuth = OAuthHandler(api_key, api_secret)\n",
    "        oAuth.set_access_token(access_token, access_token_secret)\n",
    "        # inicializa el stream\n",
    "        streamTwitts = Stream(oAuth, listener)\n",
    "        \n",
    "        # asigna filtros al stream\n",
    "        streamTwitts.filter(track=palabrasClave)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
